## Caching in Spark

By default, Spark lazily evaluates transformations. If we reuse a DataFrame multiple times, it is recomputed every single time unless you cache or persist it.

Caching/Persisting stores intermediate results in memory or disk, so they can be reused efficiently.

So caching can be used for simple reuse but persisting is mostly used for advanced fine tuning the cache memory. Caching can have only one storage level and that is `MEMORY_AND_DISK` but persisting can have multiple storage levels like `MEMORY_ONLY`, `DISK_ONLY`, etc.

Both cache() and persist() are lazy — data isn't actually cached until an action is triggered (like .count() or .show()).

### What Happens Internally When we Call `cache()` or `persist()`?

Spark marks the DataFrame or RDD for caching or persisting.

But no data is stored yet — caching is lazy.

Only when we run an action (like `.count()`, `.collect()`, `.show()`), Spark executes the computation and then stores the result.

Spark caches each partition separately. If one partition is recomputed (due to eviction or node failure), only that partition is re-evaluated, not the entire dataset.

### When Is Cache Cleared?

- When you call .unpersist(),

- When Spark decides to evict old data due to memory pressure (LRU cache)

- When the application ends

## Spark Architecture

Spark breaks a large job into smaller tasks and runs them in parallel across a cluster of machines (called executors).

**Core components**
| Component | Role |
| ------------------------- | ------------------------------------------------------------------ |
| **Driver Program** | Orchestrates execution; contains your main Spark code |
| **Cluster Manager** | Allocates resources to Spark applications (e.g., YARN, Kubernetes) |
| **Executors** | Run tasks assigned by the driver and store data |
| **Tasks** | Individual units of work (on partitions) that run on executors |
| **Jobs → Stages → Tasks** | Logical flow of execution from start to finish |

How It Works:
Spark splits data into partitions

Each partition is processed by a different executor in parallel

Results are shuffled, aggregated, or joined as needed
